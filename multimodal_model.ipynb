{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df884125",
   "metadata": {},
   "source": [
    "## 1. Importar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4d1350f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU disponible: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de reproducibilidad\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6a4364",
   "metadata": {},
   "source": [
    "## 2. Cargar y Preparar Datos Tabulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82fa22e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del dataset: (44100, 22)\n",
      "\n",
      "Clases de enfermedades: 31\n",
      "\n",
      "Distribución de clases:\n",
      "Disease_Prediction\n",
      "Parvovirus               7500\n",
      "Flu                      4200\n",
      "Distemper                3600\n",
      "Cough                    3300\n",
      "Gastroenteritis          2700\n",
      "Respiratory Infection    2700\n",
      "Leukemia                 2400\n",
      "Peritonitis              2400\n",
      "Leptospirosis            2100\n",
      "Herpes                   2100\n",
      "Pancreatitis             1200\n",
      "Hepatitis                1200\n",
      "Panleukopenia             900\n",
      "Asthma                    900\n",
      "Intestinal Parasites      600\n",
      "Lyme Disease              600\n",
      "Fungal Infection          600\n",
      "Respiratory Disease       600\n",
      "Heartworm                 600\n",
      "Chlamydia                 600\n",
      "Arthritis                 300\n",
      "Ringworm                  300\n",
      "Tick-Borne Disease        300\n",
      "Kidney Disease            300\n",
      "Allergic Rhinitis         300\n",
      "IBD                       300\n",
      "Bronchitis                300\n",
      "Conjunctivitis            300\n",
      "Hyperthyroidism           300\n",
      "Coronavirus               300\n",
      "FIV                       300\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Clases de enfermedades: 31\n",
      "\n",
      "Distribución de clases:\n",
      "Disease_Prediction\n",
      "Parvovirus               7500\n",
      "Flu                      4200\n",
      "Distemper                3600\n",
      "Cough                    3300\n",
      "Gastroenteritis          2700\n",
      "Respiratory Infection    2700\n",
      "Leukemia                 2400\n",
      "Peritonitis              2400\n",
      "Leptospirosis            2100\n",
      "Herpes                   2100\n",
      "Pancreatitis             1200\n",
      "Hepatitis                1200\n",
      "Panleukopenia             900\n",
      "Asthma                    900\n",
      "Intestinal Parasites      600\n",
      "Lyme Disease              600\n",
      "Fungal Infection          600\n",
      "Respiratory Disease       600\n",
      "Heartworm                 600\n",
      "Chlamydia                 600\n",
      "Arthritis                 300\n",
      "Ringworm                  300\n",
      "Tick-Borne Disease        300\n",
      "Kidney Disease            300\n",
      "Allergic Rhinitis         300\n",
      "IBD                       300\n",
      "Bronchitis                300\n",
      "Conjunctivitis            300\n",
      "Hyperthyroidism           300\n",
      "Coronavirus               300\n",
      "FIV                       300\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos tabulares\n",
    "df = pd.read_csv('./data/animal_disease_prediction_cleaned.csv')\n",
    "\n",
    "print(f\"Forma del dataset: {df.shape}\")\n",
    "print(f\"\\nClases de enfermedades: {df['Disease_Prediction'].nunique()}\")\n",
    "print(f\"\\nDistribución de clases:\")\n",
    "print(df['Disease_Prediction'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f14c3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos después del filtrado: (42600, 23)\n",
      "\n",
      "Clases únicas de imágenes: 13\n"
     ]
    }
   ],
   "source": [
    "# Mapear enfermedades a las categorías de imágenes disponibles\n",
    "disease_to_image_class = {\n",
    "    'Parvovirus': 'Parvovirus in Dog',\n",
    "    'Respiratory Infection': 'Eye Infection in Cat',\n",
    "    'Gastroenteritis': 'Parvovirus in Dog',\n",
    "    'Fungal Infection': 'Fungal Infection in Cat',\n",
    "    'Lyme Disease': 'Tick Infestation in Dog',\n",
    "    'Intestinal Parasites': 'Worm Infection in Cat',\n",
    "    'Distemper': 'Distemper in Dog',\n",
    "    'Cough': 'Kennel Cough in Dog',\n",
    "    'Ringworm': 'Ringworm in Cat',\n",
    "    'Tick-Borne Disease': 'Tick Infestation in Dog',\n",
    "    'Herpes': 'Eye Infection in Cat',\n",
    "    'Leukemia': 'Feline Leukemia',\n",
    "    'Heartworm': 'Kennel Cough in Dog',\n",
    "    'Peritonitis': 'Feline Panleukopenia',\n",
    "    'Conjunctivitis': 'Eye Infection in Cat',\n",
    "    'Bronchitis': 'Kennel Cough in Dog',\n",
    "    'Flu': 'Eye Infection in Cat',\n",
    "    'Pancreatitis': 'Worm Infection in Cat',\n",
    "    'IBD': 'Worm Infection in Cat',\n",
    "    'Allergic Rhinitis': 'Skin Allergy in Dog',\n",
    "    'Kidney Disease': 'Urinary Tract Infection in Cat',\n",
    "    'Arthritis': 'Hot Spots in Dog',\n",
    "    'Chlamydia': 'Eye Infection in Cat',\n",
    "    'Coronavirus': 'Feline Panleukopenia',\n",
    "    'Asthma': 'Eye Infection in Cat',\n",
    "    'Hyperthyroidism': 'Feline Leukemia',\n",
    "    'Hepatitis': 'Parvovirus in Dog',\n",
    "    'Leptospirosis': 'Parvovirus in Dog',\n",
    "    'FIV': 'Feline Leukemia'\n",
    "}\n",
    "\n",
    "df['Image_Class'] = df['Disease_Prediction'].map(disease_to_image_class)\n",
    "\n",
    "# Filtrar solo las enfermedades que tienen mapeo a imágenes\n",
    "df = df[df['Image_Class'].notna()].reset_index(drop=True)\n",
    "\n",
    "print(f\"Datos después del filtrado: {df.shape}\")\n",
    "print(f\"\\nClases únicas de imágenes: {df['Image_Class'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c6eb80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número de características tabulares: 21\n",
      "Número de clases: 29\n",
      "Clases: ['Allergic Rhinitis' 'Arthritis' 'Asthma' 'Bronchitis' 'Chlamydia'\n",
      " 'Conjunctivitis' 'Coronavirus' 'Cough' 'Distemper' 'FIV' 'Flu'\n",
      " 'Fungal Infection' 'Gastroenteritis' 'Heartworm' 'Hepatitis' 'Herpes'\n",
      " 'Hyperthyroidism' 'IBD' 'Intestinal Parasites' 'Kidney Disease'\n",
      " 'Leptospirosis' 'Leukemia' 'Lyme Disease' 'Pancreatitis' 'Parvovirus'\n",
      " 'Peritonitis' 'Respiratory Infection' 'Ringworm' 'Tick-Borne Disease']\n"
     ]
    }
   ],
   "source": [
    "# Preparar características tabulares\n",
    "# Codificar variables categóricas\n",
    "label_encoders = {}\n",
    "categorical_cols = ['Animal_Type', 'Breed', 'Gender', 'Symptom_1', 'Symptom_2', 'Symptom_3', 'Symptom_4']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col + '_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Seleccionar características para el modelo\n",
    "feature_cols = [\n",
    "    'Animal_Type_encoded', 'Breed_encoded', 'Age', 'Gender_encoded', 'Weight',\n",
    "    'Symptom_1_encoded', 'Symptom_2_encoded', 'Symptom_3_encoded', 'Symptom_4_encoded',\n",
    "    'Appetite_Loss', 'Vomiting', 'Diarrhea', 'Coughing', 'Labored_Breathing',\n",
    "    'Lameness', 'Skin_Lesions', 'Nasal_Discharge', 'Eye_Discharge',\n",
    "    'Body_Temperature', 'Heart_Rate', 'Duration_days'\n",
    "]\n",
    "\n",
    "X_tabular = df[feature_cols].values\n",
    "\n",
    "# Codificar etiquetas de enfermedades\n",
    "disease_encoder = LabelEncoder()\n",
    "y_labels = disease_encoder.fit_transform(df['Disease_Prediction'])\n",
    "num_classes = len(disease_encoder.classes_)\n",
    "\n",
    "print(f\"\\nNúmero de características tabulares: {X_tabular.shape[1]}\")\n",
    "print(f\"Número de clases: {num_classes}\")\n",
    "print(f\"Clases: {disease_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b56e2",
   "metadata": {},
   "source": [
    "## 3. Preparar Datos de Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e0aa691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando referencias a imágenes...\n",
      "Procesadas 1000/42600 muestras\n",
      "Procesadas 1000/42600 muestras\n",
      "Procesadas 2000/42600 muestras\n",
      "Procesadas 2000/42600 muestras\n",
      "Procesadas 3000/42600 muestras\n",
      "Procesadas 3000/42600 muestras\n",
      "Procesadas 4000/42600 muestras\n",
      "Procesadas 4000/42600 muestras\n",
      "Procesadas 5000/42600 muestras\n",
      "Procesadas 5000/42600 muestras\n",
      "Procesadas 6000/42600 muestras\n",
      "Procesadas 6000/42600 muestras\n",
      "Procesadas 7000/42600 muestras\n",
      "Procesadas 7000/42600 muestras\n",
      "Procesadas 8000/42600 muestras\n",
      "Procesadas 8000/42600 muestras\n",
      "Procesadas 9000/42600 muestras\n",
      "Procesadas 9000/42600 muestras\n",
      "Procesadas 10000/42600 muestras\n",
      "Procesadas 10000/42600 muestras\n",
      "Procesadas 11000/42600 muestras\n",
      "Procesadas 11000/42600 muestras\n",
      "Procesadas 12000/42600 muestras\n",
      "Procesadas 12000/42600 muestras\n",
      "Procesadas 13000/42600 muestras\n",
      "Procesadas 13000/42600 muestras\n",
      "Procesadas 14000/42600 muestras\n",
      "Procesadas 14000/42600 muestras\n",
      "Procesadas 15000/42600 muestras\n",
      "Procesadas 15000/42600 muestras\n",
      "Procesadas 16000/42600 muestras\n",
      "Procesadas 16000/42600 muestras\n",
      "Procesadas 17000/42600 muestras\n",
      "Procesadas 17000/42600 muestras\n",
      "Procesadas 18000/42600 muestras\n",
      "Procesadas 18000/42600 muestras\n",
      "Procesadas 19000/42600 muestras\n",
      "Procesadas 19000/42600 muestras\n",
      "Procesadas 20000/42600 muestras\n",
      "Procesadas 20000/42600 muestras\n",
      "Procesadas 21000/42600 muestras\n",
      "Procesadas 21000/42600 muestras\n",
      "Procesadas 22000/42600 muestras\n",
      "Procesadas 22000/42600 muestras\n",
      "Procesadas 23000/42600 muestras\n",
      "Procesadas 23000/42600 muestras\n",
      "Procesadas 24000/42600 muestras\n",
      "Procesadas 24000/42600 muestras\n",
      "Procesadas 25000/42600 muestras\n",
      "Procesadas 25000/42600 muestras\n",
      "Procesadas 26000/42600 muestras\n",
      "Procesadas 26000/42600 muestras\n",
      "Procesadas 27000/42600 muestras\n",
      "Procesadas 27000/42600 muestras\n",
      "Procesadas 28000/42600 muestras\n",
      "Procesadas 28000/42600 muestras\n",
      "Procesadas 29000/42600 muestras\n",
      "Procesadas 29000/42600 muestras\n",
      "Procesadas 30000/42600 muestras\n",
      "Procesadas 30000/42600 muestras\n",
      "Procesadas 31000/42600 muestras\n",
      "Procesadas 31000/42600 muestras\n",
      "Procesadas 32000/42600 muestras\n",
      "Procesadas 32000/42600 muestras\n",
      "Procesadas 33000/42600 muestras\n",
      "Procesadas 33000/42600 muestras\n",
      "Procesadas 34000/42600 muestras\n",
      "Procesadas 34000/42600 muestras\n",
      "Procesadas 35000/42600 muestras\n",
      "Procesadas 35000/42600 muestras\n",
      "Procesadas 36000/42600 muestras\n",
      "Procesadas 36000/42600 muestras\n",
      "Procesadas 37000/42600 muestras\n",
      "Procesadas 37000/42600 muestras\n",
      "Procesadas 38000/42600 muestras\n",
      "Procesadas 38000/42600 muestras\n",
      "Procesadas 39000/42600 muestras\n",
      "Procesadas 39000/42600 muestras\n",
      "Procesadas 40000/42600 muestras\n",
      "Procesadas 40000/42600 muestras\n",
      "Procesadas 41000/42600 muestras\n",
      "Procesadas 41000/42600 muestras\n",
      "Procesadas 42000/42600 muestras\n",
      "\n",
      "Total de muestras válidas: 42600\n",
      "Forma de datos tabulares: (42600, 21)\n",
      "Forma de etiquetas: (42600,)\n",
      "Procesadas 42000/42600 muestras\n",
      "\n",
      "Total de muestras válidas: 42600\n",
      "Forma de datos tabulares: (42600, 21)\n",
      "Forma de etiquetas: (42600,)\n"
     ]
    }
   ],
   "source": [
    "# Configuración de imágenes\n",
    "IMG_SIZE = (224, 224)\n",
    "images_base_path = './data/images'\n",
    "\n",
    "# En lugar de cargar todas las imágenes en memoria, \n",
    "# guardaremos solo las rutas y las cargaremos bajo demanda\n",
    "\n",
    "print(\"Preparando referencias a imágenes...\")\n",
    "image_paths = []\n",
    "valid_indices = []\n",
    "\n",
    "for idx, image_class in enumerate(df['Image_Class']):\n",
    "    class_path = os.path.join(images_base_path, image_class)\n",
    "    \n",
    "    if not os.path.exists(class_path):\n",
    "        continue\n",
    "    \n",
    "    images_files = [f for f in os.listdir(class_path) \n",
    "                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    if not images_files:\n",
    "        continue\n",
    "    \n",
    "    # Seleccionar imagen aleatoria y guardar su ruta\n",
    "    img_file = np.random.choice(images_files)\n",
    "    img_path = os.path.join(class_path, img_file)\n",
    "    image_paths.append(img_path)\n",
    "    valid_indices.append(idx)\n",
    "    \n",
    "    if (idx + 1) % 1000 == 0:\n",
    "        print(f\"Procesadas {idx + 1}/{len(df)} muestras\")\n",
    "\n",
    "# Filtrar datos tabulares y etiquetas\n",
    "X_tabular_filtered = X_tabular[valid_indices]\n",
    "y_labels_filtered = y_labels[valid_indices]\n",
    "\n",
    "print(f\"\\nTotal de muestras válidas: {len(image_paths)}\")\n",
    "print(f\"Forma de datos tabulares: {X_tabular_filtered.shape}\")\n",
    "print(f\"Forma de etiquetas: {y_labels_filtered.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4885fee1",
   "metadata": {},
   "source": [
    "## 4. División de Datos y Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1eea1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "División de datos:\n",
      "Entrenamiento: 29837 muestras (70.0%)\n",
      "Validación: 6373 muestras (15.0%)\n",
      "Prueba: 6390 muestras (15.0%)\n",
      "\n",
      "Forma de y_train_cat: (29837, 29)\n"
     ]
    }
   ],
   "source": [
    "# Dividir datos en entrenamiento, validación y prueba\n",
    "# Primero separar test set (15%)\n",
    "img_paths_temp, img_paths_test, X_tab_temp, X_tab_test, y_temp, y_test = train_test_split(\n",
    "    image_paths, X_tabular_filtered, y_labels_filtered, test_size=0.15, random_state=42, stratify=y_labels_filtered\n",
    ")\n",
    "\n",
    "# Luego dividir entrenamiento y validación (70% train, 15% val)\n",
    "img_paths_train, img_paths_val, X_tab_train, X_tab_val, y_train, y_val = train_test_split(\n",
    "    img_paths_temp, X_tab_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"División de datos:\")\n",
    "print(f\"Entrenamiento: {len(img_paths_train)} muestras ({len(img_paths_train)/len(image_paths)*100:.1f}%)\")\n",
    "print(f\"Validación: {len(img_paths_val)} muestras ({len(img_paths_val)/len(image_paths)*100:.1f}%)\")\n",
    "print(f\"Prueba: {len(img_paths_test)} muestras ({len(img_paths_test)/len(image_paths)*100:.1f}%)\")\n",
    "\n",
    "# Normalizar datos tabulares\n",
    "scaler = StandardScaler()\n",
    "X_tab_train = scaler.fit_transform(X_tab_train)\n",
    "X_tab_val = scaler.transform(X_tab_val)\n",
    "X_tab_test = scaler.transform(X_tab_test)\n",
    "\n",
    "# Convertir etiquetas a categorical\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_val_cat = to_categorical(y_val, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "print(f\"\\nForma de y_train_cat: {y_train_cat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90c318d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando generadores de datos...\n",
      "\n",
      "✓ Generadores creados exitosamente:\n",
      "  - Train: 933 batches\n",
      "  - Val: 200 batches\n",
      "  - Test: 200 batches\n"
     ]
    }
   ],
   "source": [
    "# Crear generador de datos personalizado para modelo multimodal\n",
    "class MultimodalDataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Generador que carga imágenes bajo demanda y combina con datos tabulares\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, tabular_data, labels, batch_size=32, \n",
    "                 img_size=(224, 224), shuffle=True, augment=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.tabular_data = tabular_data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.indexes = np.arange(len(self.image_paths))\n",
    "        \n",
    "        # Data augmentation (solo para entrenamiento)\n",
    "        if self.augment:\n",
    "            self.datagen = ImageDataGenerator(\n",
    "                rotation_range=15,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1,\n",
    "                zoom_range=0.1,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest'\n",
    "            )\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Número de batches por época\"\"\"\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Genera un batch de datos\"\"\"\n",
    "        # Obtener índices del batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        \n",
    "        # Cargar y preparar datos del batch\n",
    "        batch_images = np.zeros((len(indexes), *self.img_size, 3), dtype=np.float32)\n",
    "        batch_tabular = self.tabular_data[indexes].astype(np.float32)\n",
    "        batch_labels = self.labels[indexes].astype(np.float32)\n",
    "        \n",
    "        # Cargar imágenes\n",
    "        for i, idx in enumerate(indexes):\n",
    "            try:\n",
    "                img = load_img(self.image_paths[idx], target_size=self.img_size)\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                \n",
    "                # Aplicar augmentation si está habilitado\n",
    "                if self.augment:\n",
    "                    img_array = self.datagen.random_transform(img_array)\n",
    "                \n",
    "                batch_images[i] = img_array\n",
    "            except Exception as e:\n",
    "                print(f\"Error cargando imagen {self.image_paths[idx]}: {e}\")\n",
    "                # Usar imagen en blanco si falla la carga\n",
    "                batch_images[i] = np.zeros((*self.img_size, 3))\n",
    "        \n",
    "        # Retornar como diccionario para compatibilidad con Keras 3.x\n",
    "        return {'image_input': batch_images, 'tabular_input': batch_tabular}, batch_labels\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Mezclar índices al final de cada época\"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "# Crear generadores\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(\"Creando generadores de datos...\")\n",
    "train_generator = MultimodalDataGenerator(\n",
    "    img_paths_train, X_tab_train, y_train_cat,\n",
    "    batch_size=BATCH_SIZE, shuffle=True, augment=True\n",
    ")\n",
    "\n",
    "val_generator = MultimodalDataGenerator(\n",
    "    img_paths_val, X_tab_val, y_val_cat,\n",
    "    batch_size=BATCH_SIZE, shuffle=False, augment=False\n",
    ")\n",
    "\n",
    "test_generator = MultimodalDataGenerator(\n",
    "    img_paths_test, X_tab_test, y_test_cat,\n",
    "    batch_size=BATCH_SIZE, shuffle=False, augment=False\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Generadores creados exitosamente:\")\n",
    "print(f\"  - Train: {len(train_generator)} batches\")\n",
    "print(f\"  - Val: {len(val_generator)} batches\")\n",
    "print(f\"  - Test: {len(test_generator)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d54159b",
   "metadata": {},
   "source": [
    "## 5. Construcción del Modelo Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63cafab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CREANDO MODELO MULTIMODAL\n",
      "======================================================================\n",
      "Intentando cargar EfficientNetV2B3...\n",
      "✓ EfficientNetV2B3 con pesos de ImageNet cargado exitosamente\n",
      "Capas entrenables en CNN: 50/410\n",
      "======================================================================\n",
      "✓ EfficientNetV2B3 con pesos de ImageNet cargado exitosamente\n",
      "Capas entrenables en CNN: 50/410\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MultimodalModel\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MultimodalModel\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ tabular_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ image_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tab_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,816</span> │ tabular_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ efficientnetv2-b3   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,930,622</span> │ image_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tab_bn_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ tab_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ img_dropout_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ efficientnetv2-b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tab_dropout_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ tab_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ img_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">786,944</span> │ img_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tab_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ tab_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ img_bn_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ img_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tab_bn_2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ tab_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ img_dropout_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ img_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tab_dropout_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ tab_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ img_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ img_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tab_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ tab_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ img_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ tab_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion_dense_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ fusion[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion_bn_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ fusion_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion_dropout_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fusion_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion_dense_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ fusion_dropout_1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion_bn_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ fusion_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion_dropout_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fusion_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,741</span> │ fusion_dropout_2… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ tabular_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ image_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tab_dense_1 (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m2,816\u001b[0m │ tabular_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ efficientnetv2-b3   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)      │ \u001b[38;5;34m12,930,622\u001b[0m │ image_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tab_bn_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ tab_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ img_dropout_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ efficientnetv2-b… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tab_dropout_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ tab_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ img_dense_1 (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m786,944\u001b[0m │ img_dropout_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tab_dense_2 (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ tab_dropout_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ img_bn_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ img_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tab_bn_2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ tab_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ img_dropout_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ img_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tab_dropout_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ tab_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ img_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ img_dropout_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tab_embedding       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m8,320\u001b[0m │ tab_dropout_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ img_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ tab_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion_dense_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m98,560\u001b[0m │ fusion[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion_bn_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ fusion_dense_1[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion_dropout_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ fusion_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion_dense_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ fusion_dropout_1… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion_bn_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ fusion_dense_2[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion_dropout_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ fusion_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        │      \u001b[38;5;34m3,741\u001b[0m │ fusion_dropout_2… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,007,835</span> (53.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,007,835\u001b[0m (53.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,916,571</span> (14.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,916,571\u001b[0m (14.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,091,264</span> (38.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m10,091,264\u001b[0m (38.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_multimodal_model(img_shape, tabular_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Crea un modelo multimodal que combina:\n",
    "    - Branch de CNN para imágenes (EfficientNetB3)\n",
    "    - Branch de red densa para datos tabulares\n",
    "    - Fusión por concatenación\n",
    "    - Clasificador final\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========== BRANCH DE IMÁGENES ==========\n",
    "    # Crear input de imagen\n",
    "    input_img = layers.Input(shape=img_shape, name='image_input')\n",
    "    \n",
    "    # SOLUCIÓN: Usar EfficientNetV2 o ResNet como alternativa\n",
    "    # Si EfficientNetB3 falla, usamos una arquitectura compatible\n",
    "    try:\n",
    "        from tensorflow.keras.applications import EfficientNetV2B3\n",
    "        print(\"Intentando cargar EfficientNetV2B3...\")\n",
    "        base_cnn_model = EfficientNetV2B3(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=img_shape,\n",
    "            pooling='avg'\n",
    "        )\n",
    "        print(\"✓ EfficientNetV2B3 con pesos de ImageNet cargado exitosamente\")\n",
    "    except Exception as e1:\n",
    "        print(f\"⚠ EfficientNetV2 no disponible: {e1}\")\n",
    "        try:\n",
    "            from tensorflow.keras.applications import ResNet50\n",
    "            print(\"Intentando cargar ResNet50 como alternativa...\")\n",
    "            base_cnn_model = ResNet50(\n",
    "                include_top=False,\n",
    "                weights='imagenet',\n",
    "                input_shape=img_shape,\n",
    "                pooling='avg'\n",
    "            )\n",
    "            print(\"✓ ResNet50 con pesos de ImageNet cargado exitosamente\")\n",
    "        except Exception as e2:\n",
    "            print(f\"⚠ ResNet50 también falló: {e2}\")\n",
    "            print(\"Usando EfficientNetB3 sin pesos pre-entrenados...\")\n",
    "            base_cnn_model = EfficientNetB3(\n",
    "                include_top=False,\n",
    "                weights=None,\n",
    "                input_shape=img_shape,\n",
    "                pooling='avg'\n",
    "            )\n",
    "    \n",
    "    # Aplicar el CNN a la entrada\n",
    "    x_img = base_cnn_model(input_img)\n",
    "    \n",
    "    # Congelar capas iniciales (fine-tuning)\n",
    "    trainable_layers = min(50, len(base_cnn_model.layers))\n",
    "    for layer in base_cnn_model.layers[:-trainable_layers]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    print(f\"Capas entrenables en CNN: {sum([1 for layer in base_cnn_model.layers if layer.trainable])}/{len(base_cnn_model.layers)}\")\n",
    "    \n",
    "    # Capas adicionales para imagen\n",
    "    x_img = layers.Dropout(0.3, name='img_dropout_1')(x_img)\n",
    "    x_img = layers.Dense(512, activation='relu', name='img_dense_1')(x_img)\n",
    "    x_img = layers.BatchNormalization(name='img_bn_1')(x_img)\n",
    "    x_img = layers.Dropout(0.3, name='img_dropout_2')(x_img)\n",
    "    img_embedding = layers.Dense(256, activation='relu', name='img_embedding')(x_img)\n",
    "    \n",
    "    # ========== BRANCH TABULAR ==========\n",
    "    input_tab = layers.Input(shape=(tabular_shape,), name='tabular_input')\n",
    "    \n",
    "    x_tab = layers.Dense(128, activation='relu', name='tab_dense_1')(input_tab)\n",
    "    x_tab = layers.BatchNormalization(name='tab_bn_1')(x_tab)\n",
    "    x_tab = layers.Dropout(0.4, name='tab_dropout_1')(x_tab)\n",
    "    x_tab = layers.Dense(64, activation='relu', name='tab_dense_2')(x_tab)\n",
    "    x_tab = layers.BatchNormalization(name='tab_bn_2')(x_tab)\n",
    "    x_tab = layers.Dropout(0.4, name='tab_dropout_2')(x_tab)\n",
    "    tab_embedding = layers.Dense(128, activation='relu', name='tab_embedding')(x_tab)\n",
    "    \n",
    "    # ========== FUSIÓN MULTIMODAL ==========\n",
    "    # Concatenación de embeddings\n",
    "    fused = layers.Concatenate(name='fusion')([img_embedding, tab_embedding])\n",
    "    \n",
    "    # ========== META-MODELO (Clasificador Final) ==========\n",
    "    x = layers.Dense(256, activation='relu', name='fusion_dense_1')(fused)\n",
    "    x = layers.BatchNormalization(name='fusion_bn_1')(x)\n",
    "    x = layers.Dropout(0.4, name='fusion_dropout_1')(x)\n",
    "    x = layers.Dense(128, activation='relu', name='fusion_dense_2')(x)\n",
    "    x = layers.BatchNormalization(name='fusion_bn_2')(x)\n",
    "    x = layers.Dropout(0.3, name='fusion_dropout_2')(x)\n",
    "    \n",
    "    # Capa de salida\n",
    "    output = layers.Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    \n",
    "    # Crear modelo\n",
    "    model = Model(inputs=[input_img, input_tab], outputs=output, name='MultimodalModel')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Crear el modelo\n",
    "print(\"=\"*70)\n",
    "print(\"CREANDO MODELO MULTIMODAL\")\n",
    "print(\"=\"*70)\n",
    "model = create_multimodal_model(\n",
    "    img_shape=(224, 224, 3),\n",
    "    tabular_shape=X_tab_train.shape[1],\n",
    "    num_classes=num_classes\n",
    ")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3401cde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "Arquitectura del modelo guardada en 'outputs/multimodal_architecture.png'\n",
      "Arquitectura del modelo guardada en 'outputs/multimodal_architecture.png'\n"
     ]
    }
   ],
   "source": [
    "# Visualizar arquitectura del modelo\n",
    "keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='outputs/multimodal_architecture.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=True,\n",
    "    dpi=96\n",
    ")\n",
    "\n",
    "print(\"Arquitectura del modelo guardada en 'outputs/multimodal_architecture.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d1f8a5",
   "metadata": {},
   "source": [
    "## 6. Compilación y Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15ba7c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo compilado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Compilar modelo\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Modelo compilado exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f62e6c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callbacks configurados\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'outputs/best_multimodal_model.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configurados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c9c5286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento...\n",
      "\n",
      "Configuración:\n",
      "  - Épocas máximas: 100\n",
      "  - Batch size: 32\n",
      "  - Batches por época (train): 933\n",
      "  - Batches por época (val): 200\n",
      "======================================================================\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - accuracy: 0.0716 - auc: 0.5746 - loss: 3.9320 - precision: 0.1203 - recall: 0.0085\n",
      "Epoch 1: val_accuracy improved from None to 0.48454, saving model to outputs/best_multimodal_model.keras\n",
      "\n",
      "Epoch 1: val_accuracy improved from None to 0.48454, saving model to outputs/best_multimodal_model.keras\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m566s\u001b[0m 594ms/step - accuracy: 0.1306 - auc: 0.6567 - loss: 3.4948 - precision: 0.2959 - recall: 0.0264 - val_accuracy: 0.4845 - val_auc: 0.9497 - val_loss: 1.7391 - val_precision: 0.8123 - val_recall: 0.1514 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m566s\u001b[0m 594ms/step - accuracy: 0.1306 - auc: 0.6567 - loss: 3.4948 - precision: 0.2959 - recall: 0.0264 - val_accuracy: 0.4845 - val_auc: 0.9497 - val_loss: 1.7391 - val_precision: 0.8123 - val_recall: 0.1514 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607ms/step - accuracy: 0.3182 - auc: 0.8528 - loss: 2.4240 - precision: 0.5198 - recall: 0.1257\n",
      "Epoch 2: val_accuracy improved from 0.48454 to 0.68555, saving model to outputs/best_multimodal_model.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.48454 to 0.68555, saving model to outputs/best_multimodal_model.keras\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 686ms/step - accuracy: 0.3641 - auc: 0.8803 - loss: 2.2246 - precision: 0.5644 - recall: 0.1708 - val_accuracy: 0.6855 - val_auc: 0.9865 - val_loss: 0.9939 - val_precision: 0.8940 - val_recall: 0.5373 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 686ms/step - accuracy: 0.3641 - auc: 0.8803 - loss: 2.2246 - precision: 0.5644 - recall: 0.1708 - val_accuracy: 0.6855 - val_auc: 0.9865 - val_loss: 0.9939 - val_precision: 0.8940 - val_recall: 0.5373 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - accuracy: 0.4676 - auc: 0.9304 - loss: 1.7664 - precision: 0.6484 - recall: 0.2861\n",
      "Epoch 3: val_accuracy improved from 0.68555 to 0.81280, saving model to outputs/best_multimodal_model.keras\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.68555 to 0.81280, saving model to outputs/best_multimodal_model.keras\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m573s\u001b[0m 614ms/step - accuracy: 0.4990 - auc: 0.9408 - loss: 1.6460 - precision: 0.6740 - recall: 0.3193 - val_accuracy: 0.8128 - val_auc: 0.9963 - val_loss: 0.5898 - val_precision: 0.9429 - val_recall: 0.6914 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m573s\u001b[0m 614ms/step - accuracy: 0.4990 - auc: 0.9408 - loss: 1.6460 - precision: 0.6740 - recall: 0.3193 - val_accuracy: 0.8128 - val_auc: 0.9963 - val_loss: 0.5898 - val_precision: 0.9429 - val_recall: 0.6914 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.5766 - auc: 0.9631 - loss: 1.3426 - precision: 0.7321 - recall: 0.4130\n",
      "Epoch 4: val_accuracy improved from 0.81280 to 0.92170, saving model to outputs/best_multimodal_model.keras\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.81280 to 0.92170, saving model to outputs/best_multimodal_model.keras\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 671ms/step - accuracy: 0.5965 - auc: 0.9670 - loss: 1.2736 - precision: 0.7385 - recall: 0.4352 - val_accuracy: 0.9217 - val_auc: 0.9990 - val_loss: 0.3541 - val_precision: 0.9578 - val_recall: 0.8018 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 671ms/step - accuracy: 0.5965 - auc: 0.9670 - loss: 1.2736 - precision: 0.7385 - recall: 0.4352 - val_accuracy: 0.9217 - val_auc: 0.9990 - val_loss: 0.3541 - val_precision: 0.9578 - val_recall: 0.8018 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659ms/step - accuracy: 0.6572 - auc: 0.9768 - loss: 1.0728 - precision: 0.7802 - recall: 0.5160\n",
      "Epoch 5: val_accuracy improved from 0.92170 to 0.96391, saving model to outputs/best_multimodal_model.keras\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.92170 to 0.96391, saving model to outputs/best_multimodal_model.keras\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m690s\u001b[0m 740ms/step - accuracy: 0.6698 - auc: 0.9790 - loss: 1.0231 - precision: 0.7855 - recall: 0.5341 - val_accuracy: 0.9639 - val_auc: 0.9998 - val_loss: 0.2080 - val_precision: 0.9811 - val_recall: 0.9223 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m690s\u001b[0m 740ms/step - accuracy: 0.6698 - auc: 0.9790 - loss: 1.0231 - precision: 0.7855 - recall: 0.5341 - val_accuracy: 0.9639 - val_auc: 0.9998 - val_loss: 0.2080 - val_precision: 0.9811 - val_recall: 0.9223 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529ms/step - accuracy: 0.7138 - auc: 0.9854 - loss: 0.8654 - precision: 0.8116 - recall: 0.5973\n",
      "Epoch 6: val_accuracy improved from 0.96391 to 0.97929, saving model to outputs/best_multimodal_model.keras\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.96391 to 0.97929, saving model to outputs/best_multimodal_model.keras\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 611ms/step - accuracy: 0.7304 - auc: 0.9868 - loss: 0.8188 - precision: 0.8218 - recall: 0.6198 - val_accuracy: 0.9793 - val_auc: 0.9999 - val_loss: 0.1207 - val_precision: 0.9826 - val_recall: 0.9736 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 611ms/step - accuracy: 0.7304 - auc: 0.9868 - loss: 0.8188 - precision: 0.8218 - recall: 0.6198 - val_accuracy: 0.9793 - val_auc: 0.9999 - val_loss: 0.1207 - val_precision: 0.9826 - val_recall: 0.9736 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - accuracy: 0.7685 - auc: 0.9901 - loss: 0.7127 - precision: 0.8445 - recall: 0.6737\n",
      "Epoch 7: val_accuracy improved from 0.97929 to 0.98415, saving model to outputs/best_multimodal_model.keras\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.97929 to 0.98415, saving model to outputs/best_multimodal_model.keras\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m576s\u001b[0m 617ms/step - accuracy: 0.7800 - auc: 0.9908 - loss: 0.6785 - precision: 0.8489 - recall: 0.6918 - val_accuracy: 0.9842 - val_auc: 1.0000 - val_loss: 0.0674 - val_precision: 0.9863 - val_recall: 0.9842 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m576s\u001b[0m 617ms/step - accuracy: 0.7800 - auc: 0.9908 - loss: 0.6785 - precision: 0.8489 - recall: 0.6918 - val_accuracy: 0.9842 - val_auc: 1.0000 - val_loss: 0.0674 - val_precision: 0.9863 - val_recall: 0.9842 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - accuracy: 0.8080 - auc: 0.9928 - loss: 0.5838 - precision: 0.8657 - recall: 0.7379\n",
      "Epoch 8: val_accuracy improved from 0.98415 to 0.99121, saving model to outputs/best_multimodal_model.keras\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.98415 to 0.99121, saving model to outputs/best_multimodal_model.keras\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 610ms/step - accuracy: 0.8146 - auc: 0.9932 - loss: 0.5648 - precision: 0.8692 - recall: 0.7471 - val_accuracy: 0.9912 - val_auc: 1.0000 - val_loss: 0.0407 - val_precision: 0.9914 - val_recall: 0.9906 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 610ms/step - accuracy: 0.8146 - auc: 0.9932 - loss: 0.5648 - precision: 0.8692 - recall: 0.7471 - val_accuracy: 0.9912 - val_auc: 1.0000 - val_loss: 0.0407 - val_precision: 0.9914 - val_recall: 0.9906 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604ms/step - accuracy: 0.8374 - auc: 0.9942 - loss: 0.4987 - precision: 0.8847 - recall: 0.7803\n",
      "Epoch 9: val_accuracy improved from 0.99121 to 0.99357, saving model to outputs/best_multimodal_model.keras\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.99121 to 0.99357, saving model to outputs/best_multimodal_model.keras\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 686ms/step - accuracy: 0.8418 - auc: 0.9947 - loss: 0.4847 - precision: 0.8862 - recall: 0.7880 - val_accuracy: 0.9936 - val_auc: 1.0000 - val_loss: 0.0236 - val_precision: 0.9936 - val_recall: 0.9933 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 686ms/step - accuracy: 0.8418 - auc: 0.9947 - loss: 0.4847 - precision: 0.8862 - recall: 0.7880 - val_accuracy: 0.9936 - val_auc: 1.0000 - val_loss: 0.0236 - val_precision: 0.9936 - val_recall: 0.9933 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - accuracy: 0.8607 - auc: 0.9954 - loss: 0.4329 - precision: 0.8973 - recall: 0.8155\n",
      "Epoch 10: val_accuracy improved from 0.99357 to 0.99827, saving model to outputs/best_multimodal_model.keras\n",
      "\n",
      "Epoch 10: val_accuracy improved from 0.99357 to 0.99827, saving model to outputs/best_multimodal_model.keras\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m573s\u001b[0m 614ms/step - accuracy: 0.8655 - auc: 0.9956 - loss: 0.4205 - precision: 0.9008 - recall: 0.8218 - val_accuracy: 0.9983 - val_auc: 1.0000 - val_loss: 0.0157 - val_precision: 0.9984 - val_recall: 0.9983 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m573s\u001b[0m 614ms/step - accuracy: 0.8655 - auc: 0.9956 - loss: 0.4205 - precision: 0.9008 - recall: 0.8218 - val_accuracy: 0.9983 - val_auc: 1.0000 - val_loss: 0.0157 - val_precision: 0.9984 - val_recall: 0.9983 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - accuracy: 0.8766 - auc: 0.9963 - loss: 0.3807 - precision: 0.9089 - recall: 0.8413\n",
      "Epoch 11: val_accuracy improved from 0.99827 to 0.99984, saving model to outputs/best_multimodal_model.keras\n",
      "\n",
      "Epoch 11: val_accuracy improved from 0.99827 to 0.99984, saving model to outputs/best_multimodal_model.keras\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m577s\u001b[0m 619ms/step - accuracy: 0.8804 - auc: 0.9964 - loss: 0.3683 - precision: 0.9107 - recall: 0.8473 - val_accuracy: 0.9998 - val_auc: 1.0000 - val_loss: 0.0103 - val_precision: 1.0000 - val_recall: 0.9997 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m933/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m577s\u001b[0m 619ms/step - accuracy: 0.8804 - auc: 0.9964 - loss: 0.3683 - precision: 0.9107 - recall: 0.8473 - val_accuracy: 0.9998 - val_auc: 1.0000 - val_loss: 0.0103 - val_precision: 1.0000 - val_recall: 0.9997 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m823/933\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:13\u001b[0m 667ms/step - accuracy: 0.8821 - auc: 0.9961 - loss: 0.3566 - precision: 0.9079 - recall: 0.8498"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  - Batches por época (val): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_generator)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m¡Entrenamiento completado!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Downloads\\test\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Downloads\\test\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Downloads\\test\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Downloads\\test\\env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Downloads\\test\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Downloads\\test\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Downloads\\test\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Downloads\\test\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Downloads\\test\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Downloads\\test\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Downloads\\test\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Downloads\\test\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Entrenar modelo usando los generadores\n",
    "EPOCHS = 100\n",
    "\n",
    "print(\"Iniciando entrenamiento...\\n\")\n",
    "print(f\"Configuración:\")\n",
    "print(f\"  - Épocas máximas: {EPOCHS}\")\n",
    "print(f\"  - Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  - Batches por época (train): {len(train_generator)}\")\n",
    "print(f\"  - Batches por época (val): {len(val_generator)}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"¡Entrenamiento completado!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc6d3b6",
   "metadata": {},
   "source": [
    "## 7. Visualización del Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db2b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar curvas de entrenamiento\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Curvas de Entrenamiento del Modelo Multimodal', fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics = ['loss', 'accuracy', 'precision', 'recall', 'auc']\n",
    "titles = ['Loss', 'Accuracy', 'Precision', 'Recall', 'AUC']\n",
    "\n",
    "for idx, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    ax.plot(history.history[metric], label=f'Train {title}', linewidth=2)\n",
    "    ax.plot(history.history[f'val_{metric}'], label=f'Val {title}', linewidth=2)\n",
    "    ax.set_xlabel('Época', fontsize=12)\n",
    "    ax.set_ylabel(title, fontsize=12)\n",
    "    ax.set_title(f'{title} vs Época', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Ocultar el subplot vacío\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f8fb50",
   "metadata": {},
   "source": [
    "## 8. Evaluación en Conjunto de Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8466b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en conjunto de prueba usando el generador\n",
    "print(\"Generando predicciones en conjunto de prueba...\")\n",
    "y_pred_proba = model.predict(test_generator, verbose=1)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# AUC-ROC (one-vs-rest)\n",
    "y_test_bin = label_binarize(y_test, classes=range(num_classes))\n",
    "auc_score = roc_auc_score(y_test_bin, y_pred_proba, average='weighted', multi_class='ovr')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MÉTRICAS EN CONJUNTO DE PRUEBA\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(f\"AUC-ROC:   {auc_score:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b80702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporte de clasificación detallado\n",
    "print(\"\\nREPORTE DE CLASIFICACIÓN DETALLADO:\\n\")\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    y_pred, \n",
    "    target_names=disease_encoder.classes_,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc676e7",
   "metadata": {},
   "source": [
    "## 9. Matriz de Confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651fe58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualizar matriz de confusión\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=disease_encoder.classes_,\n",
    "    yticklabels=disease_encoder.classes_,\n",
    "    cbar_kws={'label': 'Número de Predicciones'}\n",
    ")\n",
    "plt.title('Matriz de Confusión - Modelo Multimodal', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicción', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Valor Real', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d0bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión normalizada\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(\n",
    "    cm_normalized,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='Blues',\n",
    "    xticklabels=disease_encoder.classes_,\n",
    "    yticklabels=disease_encoder.classes_,\n",
    "    cbar_kws={'label': 'Proporción'},\n",
    "    vmin=0,\n",
    "    vmax=1\n",
    ")\n",
    "plt.title('Matriz de Confusión Normalizada - Modelo Multimodal', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicción', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Valor Real', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde118a0",
   "metadata": {},
   "source": [
    "## 10. Curvas ROC (One-vs-Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9b1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular ROC y AUC para cada clase\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Calcular micro-average ROC curve\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_pred_proba.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "print(f\"AUC-ROC Micro-Average: {roc_auc['micro']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501449bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar curvas ROC para todas las clases\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Línea diagonal (clasificador aleatorio)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Clasificador Aleatorio (AUC = 0.50)')\n",
    "\n",
    "# Curva micro-average\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=f'Micro-Average (AUC = {roc_auc[\"micro\"]:.3f})',\n",
    "    color='deeppink',\n",
    "    linestyle=':',\n",
    "    linewidth=4\n",
    ")\n",
    "\n",
    "# Curvas individuales por clase (mostrar las 10 mejores para claridad)\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, num_classes))\n",
    "sorted_classes = sorted(range(num_classes), key=lambda i: roc_auc[i], reverse=True)\n",
    "\n",
    "for idx, i in enumerate(sorted_classes[:10]):\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "        color=colors[i],\n",
    "        lw=2,\n",
    "        label=f'{disease_encoder.classes_[i]} (AUC = {roc_auc[i]:.3f})'\n",
    "    )\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)', fontsize=14, fontweight='bold')\n",
    "plt.title('Curvas ROC - Top 10 Clases con Mayor AUC', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/roc_curves_top10.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Curvas ROC guardadas en 'outputs/roc_curves_top10.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar todas las curvas ROC juntas (versión completa)\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, alpha=0.5)\n",
    "\n",
    "# Todas las curvas con transparencia\n",
    "for i in range(num_classes):\n",
    "    plt.plot(fpr[i], tpr[i], lw=1.5, alpha=0.3)\n",
    "\n",
    "# Destacar micro-average\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=f'Micro-Average ROC (AUC = {roc_auc[\"micro\"]:.3f})',\n",
    "    color='red',\n",
    "    linestyle='-',\n",
    "    linewidth=3\n",
    ")\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)', fontsize=14, fontweight='bold')\n",
    "plt.title(f'Curvas ROC - Todas las {num_classes} Clases', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/roc_curves_all.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Curvas ROC completas guardadas en 'outputs/roc_curves_all.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb38f2",
   "metadata": {},
   "source": [
    "## 11. Análisis de AUC por Clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293227a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con AUC por clase\n",
    "auc_df = pd.DataFrame({\n",
    "    'Enfermedad': disease_encoder.classes_,\n",
    "    'AUC-ROC': [roc_auc[i] for i in range(num_classes)]\n",
    "}).sort_values('AUC-ROC', ascending=False)\n",
    "\n",
    "# Visualizar AUC por clase\n",
    "plt.figure(figsize=(14, 10))\n",
    "colors = ['green' if auc >= 0.9 else 'orange' if auc >= 0.8 else 'red' for auc in auc_df['AUC-ROC']]\n",
    "bars = plt.barh(auc_df['Enfermedad'], auc_df['AUC-ROC'], color=colors, alpha=0.7)\n",
    "\n",
    "# Añadir líneas de referencia\n",
    "plt.axvline(x=0.9, color='green', linestyle='--', linewidth=2, alpha=0.5, label='Excelente (≥0.9)')\n",
    "plt.axvline(x=0.8, color='orange', linestyle='--', linewidth=2, alpha=0.5, label='Bueno (≥0.8)')\n",
    "\n",
    "# Añadir valores en las barras\n",
    "for i, (idx, row) in enumerate(auc_df.iterrows()):\n",
    "    plt.text(row['AUC-ROC'] + 0.01, i, f\"{row['AUC-ROC']:.3f}\", va='center', fontweight='bold')\n",
    "\n",
    "plt.xlabel('AUC-ROC', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Enfermedad', fontsize=14, fontweight='bold')\n",
    "plt.title('AUC-ROC por Clase (Ordenado)', fontsize=16, fontweight='bold')\n",
    "plt.xlim([0, 1.1])\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/auc_by_class.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAUC-ROC por Clase:\")\n",
    "print(auc_df.to_string(index=False))\n",
    "print(f\"\\nAUC-ROC Promedio: {auc_df['AUC-ROC'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35613547",
   "metadata": {},
   "source": [
    "## 12. Guardar Resultados y Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ee7355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar métricas en CSV\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Métrica': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC (Micro-Average)'],\n",
    "    'Valor': [accuracy, precision, recall, f1, roc_auc['micro']]\n",
    "})\n",
    "\n",
    "metrics_df.to_csv('outputs/multimodal_metrics.csv', index=False)\n",
    "auc_df.to_csv('outputs/auc_by_class.csv', index=False)\n",
    "\n",
    "print(\"Métricas guardadas en:\")\n",
    "print(\"  - outputs/multimodal_metrics.csv\")\n",
    "print(\"  - outputs/auc_by_class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1cf13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo final\n",
    "model.save('outputs/multimodal_model_final.keras')\n",
    "print(\"\\nModelo final guardado en 'outputs/multimodal_model_final.keras'\")\n",
    "\n",
    "# Guardar el scaler y encoders\n",
    "import pickle\n",
    "\n",
    "with open('outputs/preprocessing_objects.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'scaler': scaler,\n",
    "        'disease_encoder': disease_encoder,\n",
    "        'label_encoders': label_encoders,\n",
    "        'feature_cols': feature_cols,\n",
    "        'num_classes': num_classes,\n",
    "        'disease_to_image_class': disease_to_image_class\n",
    "    }, f)\n",
    "\n",
    "print(\"Objetos de preprocesamiento guardados en 'outputs/preprocessing_objects.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2860696",
   "metadata": {},
   "source": [
    "## 14. Ejemplo de Predicción con el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f0b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de predicción para nuevas muestras\n",
    "def predict_disease(model, img_array, tabular_data, disease_encoder, top_k=3):\n",
    "    \"\"\"\n",
    "    Predice la enfermedad para una nueva muestra multimodal\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo entrenado\n",
    "        img_array: Array de imagen normalizada (224, 224, 3)\n",
    "        tabular_data: Array de datos tabulares normalizados\n",
    "        disease_encoder: LabelEncoder de enfermedades\n",
    "        top_k: Número de predicciones top a retornar\n",
    "    \n",
    "    Returns:\n",
    "        Lista de tuplas (enfermedad, probabilidad)\n",
    "    \"\"\"\n",
    "    # Expandir dimensiones para batch\n",
    "    img_batch = np.expand_dims(img_array, axis=0)\n",
    "    tab_batch = np.expand_dims(tabular_data, axis=0)\n",
    "    \n",
    "    # Predecir\n",
    "    predictions = model.predict([img_batch, tab_batch], verbose=0)[0]\n",
    "    \n",
    "    # Obtener top-k predicciones\n",
    "    top_indices = np.argsort(predictions)[-top_k:][::-1]\n",
    "    top_diseases = disease_encoder.inverse_transform(top_indices)\n",
    "    top_probs = predictions[top_indices]\n",
    "    \n",
    "    return list(zip(top_diseases, top_probs))\n",
    "\n",
    "# Ejemplo con una muestra del conjunto de prueba\n",
    "# Cargar una imagen de prueba aleatoria\n",
    "sample_idx = np.random.randint(0, len(img_paths_test))\n",
    "\n",
    "# Cargar la imagen\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "sample_img = load_img(img_paths_test[sample_idx], target_size=(224, 224))\n",
    "sample_img = img_to_array(sample_img) / 255.0\n",
    "sample_tab = X_tab_test[sample_idx]\n",
    "true_label = disease_encoder.inverse_transform([y_test[sample_idx]])[0]\n",
    "\n",
    "predictions = predict_disease(model, sample_img, sample_tab, disease_encoder, top_k=5)\n",
    "\n",
    "print(\"\\nEJEMPLO DE PREDICCIÓN:\\n\")\n",
    "print(f\"Enfermedad Real: {true_label}\")\n",
    "print(\"\\nTop 5 Predicciones:\")\n",
    "for i, (disease, prob) in enumerate(predictions, 1):\n",
    "    print(f\"  {i}. {disease:30s} - {prob*100:5.2f}%\")\n",
    "\n",
    "# Visualizar la imagen de ejemplo\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(sample_img)\n",
    "plt.title(f\"Muestra de Prueba\\nReal: {true_label} | Predicción: {predictions[0][0]}\", \n",
    "\n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
